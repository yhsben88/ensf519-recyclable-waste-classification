{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc1facf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, random_split, Subset\n",
    "from torchvision import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092be9ec",
   "metadata": {},
   "source": [
    "This dataset contains a comprehensive collection of 15,000 images (each 256x256 pixels) depicting various recyclable materials, general waste, and household items across 30 distinct categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f83d2aa5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: [0.74856972 0.72743281 0.70510449]\n",
      "std: [0.30954896 0.31524588 0.33628213]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def compute_mean_std(image_folder):\n",
    "    \"\"\"Compute mean and std per channel for all images in image_folder (RGB), including subfolders.\"\"\"\n",
    "    channel_sum = np.zeros(3)\n",
    "    channel_sum_sq = np.zeros(3)\n",
    "    num_pixels = 0\n",
    "\n",
    "    for root, _, files in os.walk(image_folder):\n",
    "        for fname in files:\n",
    "            if not fname.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                continue\n",
    "            img_path = os.path.join(root, fname)\n",
    "            img = Image.open(img_path).convert('RGB')\n",
    "            img_np = np.array(img, dtype=np.float32) / 255.0\n",
    "            num_pixels += img_np.shape[0] * img_np.shape[1]\n",
    "            channel_sum += img_np.sum(axis=(0,1))\n",
    "            channel_sum_sq += (img_np ** 2).sum(axis=(0,1))\n",
    "\n",
    "    mean = channel_sum / num_pixels\n",
    "    std = np.sqrt(channel_sum_sq / num_pixels - mean**2)\n",
    "    return mean, std\n",
    "\n",
    "mean, std = compute_mean_std(\"../data/images\")  # top-level folder\n",
    "print(\"mean:\", mean)\n",
    "print(\"std:\", std)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8c45a",
   "metadata": {},
   "source": [
    "dataset has values around 0.7–0.75 for mean, which is expected for images dominated by bright backgrounds or lighter materials.\n",
    "\n",
    "std values around 0.31–0.33 mean the pixel values vary moderately around the mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e833cf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomCrop(256, padding=16),\n",
    "    transforms.RandomRotation(degrees=30), #This rotates the image by a random angle between –30 and +30 degrees.\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.74856972, 0.72743281, 0.70510449), (0.30954896, 0.31524588, 0.33628213))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.74856972, 0.72743281, 0.70510449), (0.30954896, 0.31524588, 0.33628213))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ec20ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Load Datasets (1 mark)\n",
    "data_dir = \"../data/images\"  # top-level folder containing all categories\n",
    "full_dataset = datasets.ImageFolder(root=data_dir)\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Split per class\n",
    "# -----------------------------\n",
    "random.seed(42)  # for reproducibility\n",
    "\n",
    "train_indices = []\n",
    "test_indices = []\n",
    "\n",
    "# Map from class index to list of sample indices\n",
    "class_to_indices = {i: [] for i in range(len(full_dataset.classes))}\n",
    "for idx, (_, label) in enumerate(full_dataset.samples):\n",
    "    class_to_indices[label].append(idx)\n",
    "\n",
    "for class_idx, indices in class_to_indices.items():\n",
    "    n_total = len(indices)\n",
    "    n_test = int(0.2 * n_total)\n",
    "    shuffled = indices.copy()\n",
    "    random.shuffle(shuffled)\n",
    "    test_indices.extend(shuffled[:n_test])\n",
    "    train_indices.extend(shuffled[n_test:])\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Create Subset datasets\n",
    "# -----------------------------\n",
    "train_dataset = Subset(full_dataset, train_indices)\n",
    "test_dataset = Subset(full_dataset, test_indices)\n",
    "\n",
    "# TODO: Split train into train + validation (1 mark)\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "\n",
    "# TODO: Data loaders (1 mark)\n",
    "batch_size = 32\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c3acca",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
